{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "# will use them for creating custom directory iterator\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "import json\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import DirectoryIterator, ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "#from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectoryIteratorWithBoundingBoxes(DirectoryIterator):\n",
    "    def __init__(self, directory, image_data_generator, bounding_boxes: dict = None, target_size=(256, 256),\n",
    "                 color_mode: str = 'rgb', classes=None, class_mode: str = 'categorical', batch_size: int = 32,\n",
    "                 shuffle: bool = True, seed=None, data_format=None, save_to_dir=None,\n",
    "                 save_prefix: str = '', save_format: str = 'jpeg', follow_links: bool = False):\n",
    "        super().__init__(directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size,\n",
    "                         shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links)\n",
    "        self.bounding_boxes = bounding_boxes\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=K.floatx())\n",
    "        locations = np.zeros((len(batch_x),) + (4,), dtype=K.floatx())\n",
    "\n",
    "        # build batch of image data\n",
    "        for i, j in enumerate(index_array):\n",
    "            fname = self.filenames[j]\n",
    "            img = image.load_img(os.path.join(self.directory, fname),\n",
    "                                 target_size=self.target_size)\n",
    "            x = image.img_to_array(img, data_format=self.data_format)\n",
    "            x = preprocess_input(x)\n",
    "            x = self.image_data_generator.random_transform(x)\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "\n",
    "            if self.bounding_boxes is not None:\n",
    "                bounding_box = self.bounding_boxes[fname]\n",
    "                locations[i] = np.asarray(\n",
    "                    [bounding_box['x1'], bounding_box['y1'], bounding_box['x2'], bounding_box['y2']],\n",
    "                    dtype=K.floatx())\n",
    "        # optionally save augmented images to disk for debugging purposes\n",
    "        # build batch of labels\n",
    "        if self.class_mode == 'sparse':\n",
    "            batch_y = self.classes[index_array]\n",
    "        elif self.class_mode == 'binary':\n",
    "            batch_y = self.classes[index_array].astype(K.floatx())\n",
    "        elif self.class_mode == 'categorical':\n",
    "            batch_y = np.zeros((len(batch_x), 46), dtype=K.floatx())\n",
    "            for i, label in enumerate(self.classes[index_array]):\n",
    "                batch_y[i, label] = 1.\n",
    "        else:\n",
    "            return batch_x\n",
    "\n",
    "        if self.bounding_boxes is not None:\n",
    "            return batch_x, [batch_y, locations]\n",
    "        else:\n",
    "            return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0922 01:30:16.637933 140363346077504 deprecation_wrapper.py:119] From /home/ec2-user/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0922 01:30:16.676940 140363346077504 deprecation_wrapper.py:119] From /home/ec2-user/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0922 01:30:16.680668 140363346077504 deprecation_wrapper.py:119] From /home/ec2-user/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0922 01:30:16.717753 140363346077504 deprecation_wrapper.py:119] From /home/ec2-user/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0922 01:30:17.317253 140363346077504 deprecation_wrapper.py:119] From /home/ec2-user/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0922 01:30:17.321175 140363346077504 deprecation_wrapper.py:119] From /home/ec2-user/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0922 01:30:19.690937 140363346077504 deprecation_wrapper.py:119] From /home/ec2-user/miniconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape = (200,200,3))\n",
    "\n",
    "#for layer in model_resnet.layers[:-12]:\n",
    "#    # 6 - 12 - 18 have been tried. 12 is the best.\n",
    "#    layer.trainable = False\n",
    "\n",
    "# Freeze all layers for now except last convolutional block  \n",
    "for layer in vgg16.layers[:15]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "#input = Input(shape=(200,200,3),name = 'input_shape')\n",
    "    \n",
    "x = Flatten()(vgg16.output)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "y = Dense(46, activation='softmax', name='img')(x)\n",
    "\n",
    "x_bbox = Flatten()(vgg16.output)\n",
    "x_bbox = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x_bbox)\n",
    "x_bbox = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x_bbox)\n",
    "bbox = Dense(4, kernel_initializer='normal', name='bbox')(x_bbox)\n",
    "\n",
    "final_model = Model(inputs=vgg16.input,\n",
    "                    outputs=[y, bbox])\n",
    "\n",
    "opt = SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
    "\n",
    "final_model.compile(optimizer=opt,\n",
    "                    loss={'img': 'categorical_crossentropy',\n",
    "                          'bbox': 'mean_squared_error'},\n",
    "                    metrics={'img': ['accuracy'], # default: top-5\n",
    "                             'bbox': ['mse']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/ebsvol2/data/deepfashion_keras/data/img_dicts/dict_train.json', 'r') as train_f:\n",
    "    dict_train = json.load(train_f)\n",
    "\n",
    "with open('/ebsvol2/data/deepfashion_keras/data/img_dicts/dict_val.json', 'r') as val_f:\n",
    "    dict_val = json.load(val_f)\n",
    "\n",
    "with open('/ebsvol2/data/deepfashion_keras/data/img_dicts/dict_test.json', 'r') as test_f:\n",
    "    dict_test = json.load(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 209222 images belonging to 46 classes.\n",
      "Found 40000 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"/ebsvol2/data/deepfashion_keras/data/img/train\"\n",
    "val_dir = \"/ebsvol2/data/deepfashion_keras/data/img/val\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=30.,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "train_iterator = DirectoryIteratorWithBoundingBoxes(train_dir, train_datagen, bounding_boxes=dict_train, target_size=(200, 200))\n",
    "val_iterator = DirectoryIteratorWithBoundingBoxes(val_dir, val_datagen, bounding_boxes=dict_val,target_size=(200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               patience=12,\n",
    "                               factor=0.5,\n",
    "                               verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='/home/ec2-user/GitHub/deepfashion_keras/tb_logs')\n",
    "early_stopper = EarlyStopping(monitor='val_loss',\n",
    "                              patience=30,\n",
    "                              verbose=1)\n",
    "performance_log = CSVLogger('/home/ec2-user/GitHub/deepfashion_keras/csv_logs/vgg16_10_epoch_log.csv',separator=',',append=False)\n",
    "checkpoint = ModelCheckpoint('/home/ec2-user/GitHub/deepfashion_keras/models/vgg16_10_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_generator(iterator):\n",
    "    while True:\n",
    "        batch_x, batch_y = iterator.next()\n",
    "        yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0922 01:30:47.232630 140363346077504 deprecation.py:323] From /home/ec2-user/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "/home/ec2-user/miniconda3/lib/python3.7/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    }
   ],
   "source": [
    "final_model.fit_generator(custom_generator(train_iterator),\n",
    "                          steps_per_epoch= 6538, # 209222 train records / batch size of 32\n",
    "                          epochs=10, \n",
    "                          validation_data=custom_generator(val_iterator),\n",
    "                          validation_steps= 1250, # 40000 val records/ batch size of 32\n",
    "                          verbose=2,\n",
    "                          shuffle=True,\n",
    "                          callbacks=[lr_reducer, checkpoint, early_stopper, tensorboard, performance_log],\n",
    "                          workers=12\n",
    "                         ,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should save a no top version of the model as well. pop last layers back to conv5 which is a pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_dir = \"/ebsvol2/data/deepfashion_keras/data/img/test\"\n",
    "\n",
    "\n",
    "test_iterator = DirectoryIteratorWithBoundingBoxes(test_dir, test_datagen, bounding_boxes=dict_test, target_size=(224, 224))\n",
    "scores = final_model.evaluate_generator(custom_generator(test_iterator), steps=1250)\n",
    "\n",
    "print('Multi target loss: ' + str(scores[0]))\n",
    "print('Image loss: ' + str(scores[1]))\n",
    "print('Bounding boxes loss: ' + str(scores[2]))\n",
    "print('Image accuracy: ' + str(scores[3]))\n",
    "print('Top-5 image accuracy: ' + str(scores[4]))\n",
    "print('Bounding boxes error: ' + str(scores[5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
